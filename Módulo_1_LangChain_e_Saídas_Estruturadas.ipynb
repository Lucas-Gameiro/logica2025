{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucas-Gameiro/logica2025/blob/main/M%C3%B3dulo_1_LangChain_e_Sa%C3%ADdas_Estruturadas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 1: A Base - LangChain e Saídas Estruturadas"
      ],
      "metadata": {
        "id": "ZvLjUp_fKE2z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdBgkw5kl8GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução"
      ],
      "metadata": {
        "id": "EMf0dIDtKIRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bem-vindo ao primeiro módulo do nosso tutorial! O objetivo aqui é construir a fundação para todas as técnicas avançadas que exploraremos. Antes de mergulhar em engenharia de prompt, ensembles ou fine-tuning, precisamos garantir que conseguimos nos comunicar com os Modelos de Linguagem de Grande Porte (LLMs) de forma eficiente, robusta e, mais importante, programática.\n",
        "\n",
        "Neste notebook, vamos abordar três pilares essenciais:\n",
        "1. **Configuração do Ambiente:** Como acessar LLMs poderosos através de APIs, com foco em opções gratuitas.\n",
        "2. **Orquestração com LangChain:** Uma introdução à biblioteca LangChain, que simplifica a criação de aplicações com LLMs.\n",
        "3. **Geração de Saídas Estruturadas:** A técnica crucial para transformar as respostas em texto livre dos LLMs em formatos de dados consistentes e utilizáveis, como JSON, que são a base para qualquer aplicação real.\n",
        "\n",
        "Ao final deste módulo, você terá um ambiente configurado e será capaz de instruir um LLM a retornar informações em um formato Python pré-definido, pronto para ser integrado em qualquer software."
      ],
      "metadata": {
        "id": "xAdELwFgKN07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configuração das APIs"
      ],
      "metadata": {
        "id": "reZmkDEkLAp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para interagir com a maioria dos LLMs de ponta, utilizamos uma Interface de Programação de Aplicações (API). Ela funciona como uma \"ponte\" que permite que nosso código envie requisições para o modelo e receba as respostas."
      ],
      "metadata": {
        "id": "v9TAzMqnLDC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Groq"
      ],
      "metadata": {
        "id": "hSP97LKoLEFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groq é uma plataforma de inferência de IA de alta performance. Ela oferece acesso via API a diversos modelos open-source de ponta.\n",
        "\n",
        "Ela possui 2 atrativos principais. O primeiro é que ela oferece um plano gratuito que permite rodar LLMs poderosos de forma gratuita (dentro de certos limites de uso). O segundo é a velocidade de processamento, que é extremamente rápida.\n",
        "\n",
        "Você pode criar sua conta gratuitamente ([link](console.groq.com)) e, após o login, gerar sua chave de API na aba “API Keys”. Depois de se cadastrar, siga o seguinte passo a passo:\n",
        "1. Acesse a aba **Secrets** (representada por um ícone de chave na barra lateral do Colab)\n",
        "2. Clique em **\"Adicionar novo secret\"**\n",
        "3. Defina o Nome `\"GROQ_API_KEY\"`\n",
        "4. Cole a chave de API que você gerou na plataforma\n",
        "\n",
        "Neste tutorial, vamos utilizar a API da Groq, mas voce pode usar qualquer outro modelo com integração com o langchain."
      ],
      "metadata": {
        "id": "bQGQ2VtMLK8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlUIKYkKBMt",
        "outputId": "1f38c471-ba44-4563-9ff3-876e23f529b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-core langchain-community langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_groq = ChatGroq(\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "e2DA4UxyOJL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Sabiá / Maritaca.AI"
      ],
      "metadata": {
        "id": "W7oEYi4IOTNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É uma plataforma brasileira que disponibiliza modelos de linguagem treinados em português com uma API compatível com a da OpenAI. Ao se cadastrar no serviço [(link)](https://www.maritaca.ai/), você ganha R$20,00 de crédito grátis após verificar um método de pagamento.\n",
        "\n",
        "Esse crédito inicial é suficiente para realizar o tutorial. Opcionalmente, você pode fazer uma pequena recarga (mesmo o valor mínimo) porque isso aumenta a velocidade de geração e eleva o limite de requisições por minuto consideravelmente. Não é obrigatório para seguir o tutorial, mas se você notar lentidão, essa pode ser uma solução.\n",
        "\n",
        "Por ser compatível com a API da OpenAI, usar o Sabiá é muito fácil: você pode utilizar bibliotecas pensadas para OpenAI apenas substituindo a chave de API e endpoint. Além disso, o Sabiá já suporta funcionalidades avançadas como saídas estruturadas e chamada de função de forma nativa. Ou seja, é uma alternativa local/nacional para usar LLMs poderosos a custo menor e com suporte ao português.\n",
        "\n",
        "Depois de se cadastrar, adicione a chave `MARITALK_API_KEY` á aba Secrets do Colab seguindo os mesmos passos do Groq."
      ],
      "metadata": {
        "id": "5PcTfXwZOUZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatMaritalk\n",
        "\n",
        "llm_sabia = ChatMaritalk(\n",
        "    model=\"sabiazinho-3\",\n",
        "    api_key=userdata.get('MARITALK_API_KEY'),\n",
        "    temperature=0.7,\n",
        ")"
      ],
      "metadata": {
        "id": "Ru5qPzbgO40z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Introdução ao LangChain"
      ],
      "metadata": {
        "id": "eOaTSXqNPVa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Interagindo com o Modelo"
      ],
      "metadata": {
        "id": "HC3FanWVPZ5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir aplicações com LLMs envolve mais do que apenas enviar um prompt para uma API. Frequentemente, precisamos encadear múltiplas chamadas, gerenciar o histórico da conversa, conectar o LLM a fontes de dados externas e formatar suas saídas. Fazer tudo isso manualmente pode ser complexo e repetitivo.\n",
        "\n",
        "É aqui que entra o LangChain [1]. LangChain é um framework de código aberto projetado para simplificar o desenvolvimento de aplicações baseadas em LLMs. Ele fornece um conjunto de abstrações e componentes modulares que facilitam a criação de cadeias (chains) e agentes complexos.\n",
        "\n",
        "Já vimos como instanciar ambos os modelos, para chamar eles no nosso código bastam chamar o método invoke com uma string."
      ],
      "metadata": {
        "id": "tBilnLQgPqHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = llm_groq.invoke(\"Olá, tudo bem?\")\n",
        "print(resposta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzh7UErcPXHZ",
        "outputId": "e7d13a85-dc94-4e97-f88d-79c0759d8507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='<think>\\n\\n</think>\\n\\nOlá! Estou aqui para ajudar. Como posso ser útil hoje?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 9, 'total_tokens': 32, 'completion_time': 0.095599255, 'prompt_time': 0.000496606, 'queue_time': 0.202210261, 'total_time': 0.096095861}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--0a37eb15-d2f5-4443-997f-77002fa4fed9-0' usage_metadata={'input_tokens': 9, 'output_tokens': 23, 'total_tokens': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com apenas uma linha de código, podemos interagir com as llms, com toda a complexidade da comunicação via API abstraída pelo LangChain."
      ],
      "metadata": {
        "id": "WoIh0owQP33W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Generalização de Prompts\n",
        "O langchain também oferece uma forma de criar prompts dinâmicos reutilizaveis, fazemos isso através do prompt template."
      ],
      "metadata": {
        "id": "QAP3q8WjP8dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"Escreva um poema {tamanho} sobre {tema}.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpEZP4u8P4lZ",
        "outputId": "00864d31-7d43-4931-fc2b-c7c864591f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['tamanho', 'tema'], input_types={}, partial_variables={}, template='Escreva um poema {tamanho} sobre {tema}.')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A maioria das interações através do langchain acontece através do método `invoke`. Podemos gerar o prompt para a LLM da seguinte forma:"
      ],
      "metadata": {
        "id": "Ywv6MLFHQWMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poema = prompt.invoke({\"tamanho\": \"curto\", \"tema\": \"a lua\"})\n",
        "poema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JibheUiQQZf1",
        "outputId": "a9353574-3b1a-4907-f609-e853df79a871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='Escreva um poema curto sobre a lua.')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Cadeias (Chains)"
      ],
      "metadata": {
        "id": "iMoY66avQpLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que temos um prompt dinâmico e um llm, podemos combiná-los. A forma mais idiomática e poderosa de fazer isso no LangChain é através de `chains`, utilizando o operador pipe (`|`). Isso cria um fluxo de dados legível e modular, onde a saída de um componente se torna automaticamente a entrada do próximo, simplificando a lógica."
      ],
      "metadata": {
        "id": "xn3DqAuQQsdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "dOJBEgJqRaD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = prompt.invoke({\"tamanho\": \"curto\", \"tema\": \"a lua\"})\n",
        "resposta = llm_groq.invoke(entrada)\n",
        "\n",
        "parser = StrOutputParser()\n",
        "resposta = parser.invoke(resposta)\n",
        "\n",
        "print(resposta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI_z15vWQy6Q",
        "outputId": "75ccae5a-2b6a-4f59-e2d5-eb594411da21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, the user wants me to write a short poem about the moon. Hmm, I should make it simple and sweet. Let me think about the imagery associated with the moon—maybe something about its light, the night, and perhaps some emotions it evokes.\n",
            "\n",
            "I'll start with the first stanza. Maybe something like the moon being a silver disk in the sky. Then, the second line could be about it lighting up the night. That sets a nice scene.\n",
            "\n",
            "For the second stanza, I can talk about the stars accompanying the moon and the world being quiet. That adds a peaceful feeling. Finally, I'll end with a couplet that ties the moon to the sea and the heart. That should give it a romantic touch.\n",
            "\n",
            "Let me make sure the rhyme scheme is consistent and the lines flow well. I think AABB would work here. Let me put it all together and see how it sounds.\n",
            "</think>\n",
            "\n",
            "Claro! Aqui está um poema curto sobre a lua:\n",
            "\n",
            "A lua, um disco de prata,  \n",
            "No céu azul, brilha e ilumina.  \n",
            "As estrelas, seu acompanhamento,  \n",
            "Na noite quieta, tudo encanta.  \n",
            "\n",
            "Seu brilho suave toca o mar,  \n",
            "E no coração, ecoa um sonhar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm_groq | StrOutputParser()\n",
        "resposta = chain.invoke({\"tamanho\": \"curto\", \"tema\": \"a lua\"})\n",
        "print(resposta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFGagp8NRJOA",
        "outputId": "3fa83960-f23b-431e-bd6f-af173f524d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, I need to write a short poem about the moon. Let's see, the user provided a Portuguese poem, so maybe they want something similar in English, but I should focus on the thought process of creating such a poem.\n",
            "\n",
            "First, I should think about the characteristics of the moon. It's often associated with night, light, tides, emotions, and sometimes mythology. I want to capture its beauty and maybe some of its mystical aspects.\n",
            "\n",
            "I should consider the structure. The example had four stanzas with four lines each, using a rhyme scheme. Maybe I'll follow a similar structure but in English. Let's think about the rhyme scheme—perhaps ABAB or AABB.\n",
            "\n",
            "Imagery is important. I can describe the moon as glowing, silver, maybe personify it a bit. Think about how it affects the night, the tides, and people's feelings.\n",
            "\n",
            "I should also think about the mood. The example had a calm and serene feeling, so I'll aim for that too. Maybe include elements like the night sky, stars, and the reflection on water.\n",
            "\n",
            "Let me brainstorm some lines. Start with the moon in the sky, its light, then move to its effect on the earth, maybe the tides or shadows. Then perhaps touch on emotions or inspiration.\n",
            "\n",
            "I need to make sure each stanza flows well and the rhymes are consistent. I'll try to keep the language simple and evocative.\n",
            "\n",
            "Maybe start with something like:\n",
            "\n",
            "The moon ascends the midnight sky,\n",
            "A glowing orb, so calm, so high.\n",
            "With gentle light, it fills the night,\n",
            "And chases all the dark of sight.\n",
            "\n",
            "Then move on to its reflection and the tides:\n",
            "\n",
            "Its silver beams upon the sea,\n",
            "Create a path of glistening spree.\n",
            "The waves caress the sandy shore,\n",
            "As if the moon they adore.\n",
            "\n",
            "Next, perhaps the emotional or inspirational aspect:\n",
            "\n",
            "The moon has watched through endless years,\n",
            "Through laughter, tears, and all our fears.\n",
            "It stands a constant, steadfast friend,\n",
            "Until the very end.\n",
            "\n",
            "Finally, conclude with its timeless beauty:\n",
            "\n",
            "So let us marvel at its grace,\n",
            "A beacon in the dark of space.\n",
            "The moon, a symbol pure and bright,\n",
            "Guiding us through the endless night.\n",
            "\n",
            "I think that covers the main points. Now, I'll put it all together, making sure each stanza has four lines and the rhymes are consistent.\n",
            "</think>\n",
            "\n",
            "The moon ascends the midnight sky,  \n",
            "A glowing orb, so calm, so high.  \n",
            "With gentle light, it fills the night,  \n",
            "And chases all the dark of sight.  \n",
            "\n",
            "Its silver beams upon the sea,  \n",
            "Create a path of glistening spree.  \n",
            "The waves caress the sandy shore,  \n",
            "As if the moon they adore.  \n",
            "\n",
            "The moon has watched through endless years,  \n",
            "Through laughter, tears, and all our fears.  \n",
            "It stands a constant, steadfast friend,  \n",
            "Until the very end.  \n",
            "\n",
            "So let us marvel at its grace,  \n",
            "A beacon in the dark of space.  \n",
            "The moon, a symbol pure and bright,  \n",
            "Guiding us through the endless night.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Saídas Estruturadas"
      ],
      "metadata": {
        "id": "ICAepivkR4pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. A Necessidade de Saídas Estruturadas"
      ],
      "metadata": {
        "id": "PYdITDpwR8Dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um dos maiores desafios ao usar LLMs em aplicações de software é que, por natureza, eles geram texto não estruturado. Para uma tarefa de classificação de sentimento, um LLM pode responder:\n",
        "1. \"O sentimento é positivo\"\n",
        "2. \"Positivo\"\n",
        "3. \"Com base na análise, o texto expressa um sentimento positivo.\"\n",
        "4. ...\n",
        "\n",
        "Todas essas respostas são corretas para um humano, mas a variação torna difícil para um programa processá-las de forma confiável.\n",
        "\n",
        "Quando pedimos algo a um modelo de linguagem, por padrão ele retorna texto livre, em linguagem natural, o que muitas vezes é suficiente para uma conversa ou resposta direta. No entanto, em aplicações práticas, frequentemente queremos que o modelo nos dê a resposta em um formato específico e estruturado para podermos processá-la automaticamente. Exemplos comuns:\n",
        "- Preencher campos de um formulário ou banco de dados (por exemplo, extrair de um texto o {\"nome\": ..., \"email\": ..., \"telefone\": ...} em formato JSON).\n",
        "- Listar informações em forma de tabela (CSV) ou em bullet points bem definidos.\n",
        "- Retornar um conjunto de pares chave-valor, XML ou outro formato que alguma outra parte do sistema espera.\n",
        "\n",
        "Ter um formato de saída estruturado torna a integração entre LLMs e sistemas tradicionais muito mais confiável. Se um modelo responde com um parágrafo de texto explicativo, é difícil para um programa extrair exatamente as partes relevantes sem risco de erro. Por outro lado, se conseguimos fazer o modelo responder, por exemplo, em JSON com campos definidos, podemos diretamente carregar esse JSON em uma estrutura de dados na nossa aplicação (um dicionário Python, por exemplo) e utilizar as informações de forma determinística.\n",
        "\n",
        "$$\\text{estrutura} = \\text{automação simplificada}.$$"
      ],
      "metadata": {
        "id": "b4vQl-CVSB6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Instrução via Prompt"
      ],
      "metadata": {
        "id": "297Px6usS3JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A abordagem mais direta para obter uma saída estruturada é simplesmente pedir explicitamente no prompt que o modelo formate a resposta de determinada forma. Por exemplo, podemos acrescentar às instruções algo como: \"Responda somente no formato JSON, contendo as seguintes chaves...\". Essa técnica de prompt engineering muitas vezes resolve casos simples."
      ],
      "metadata": {
        "id": "bDPaGBBrS7RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Extraia as seguintes informações do currículo abaixo:\n",
        "- Nome\n",
        "- Formação\n",
        "- Anos de experiência\n",
        "\n",
        "Formate a saída em JSON:\n",
        "{{\n",
        "    \"nome\": \"Nome do candidato\",\n",
        "    \"formacao\": \"Formação do candidato\",\n",
        "    \"anos_experiencia\": \"Anos de experiência do candidato\"\n",
        "}}\n",
        "\n",
        "Currículo:\"{resume_text}\"\n",
        "\n",
        "JSON:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"resume_text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "2o4svMe5R57f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm_groq | StrOutputParser()\n",
        "resume = \"Meu nome é João Silva, tenho 28 anos. Sou Bacharel em Ciência da Computação pela Universidade Federal de Minas Gerais (UFMG). Fui Desenvolvedor de Software na Empresa X por 5 anos e Gestor de Projetos na Empresa Y por 3 anos onde trabalho atualmente.\"\n",
        "\n",
        "resposta = chain.invoke({\"resume_text\": resume})\n",
        "print(resposta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O_H2iRiTMRt",
        "outputId": "1b73cf0e-fdd0-4eb0-bf32-56f0f9fe78a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, let me try to figure out how to approach this problem. The user provided a resume in Portuguese and wants me to extract specific information: name, education, and years of experience, and format it into a JSON structure. \n",
            "\n",
            "First, I'll start by reading the resume carefully. The name is clearly stated as \"João Silva.\" That's straightforward. Next, the education part mentions that he has a Bachelor's degree in Computer Science from the Federal University of Minas Gerais (UFMG). So, I'll note that as his formação.\n",
            "\n",
            "Now, for the anos_experiencia, I need to calculate the total years of experience. The resume says he worked as a Software Developer at Empresa X for 5 years and as a Project Manager at Empresa Y for 3 years. Adding those together, that's 5 + 3 = 8 years of experience. I should make sure to present this as a number without any additional text, just the integer 8.\n",
            "\n",
            "I also need to format the extracted information into a JSON structure as specified. The keys should be \"nome,\" \"formacao,\" and \"anos_experiencia.\" I'll ensure the values are correctly placed within quotes and the JSON syntax is accurate to avoid any errors.\n",
            "\n",
            "Before finalizing, I'll double-check the resume to confirm all the details are captured correctly. Once I'm confident, I'll present the JSON response as requested.\n",
            "</think>\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"nome\": \"João Silva\",\n",
            "    \"formacao\": \"Bacharel em Ciência da Computação pela Universidade Federal de Minas Gerais (UFMG)\",\n",
            "    \"anos_experiencia\": 8\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que ainda recebemos informações fora da estrutura (pensamento no caso do DeepSeek), porém, o tratamento desse texto é bem mais simples do que a saída comum."
      ],
      "metadata": {
        "id": "wKKiSrE3Ti0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Conversão para Objetos"
      ],
      "metadata": {
        "id": "TLH54eSeUAl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain oferece uma maneira elegante de implementar saídas estruturadas usando a biblioteca Pydantic. Pydantic permite definir a estrutura dos seus dados usando classes Python. LangChain, então, usa essa definição para:\n",
        "1. Gerar automaticamente uma instrução de formatação para o LLM.\n",
        "2. Analisar a saída de texto do LLM e convertê-la em um objeto Python.\n",
        "\n",
        "O Pydantic é uma biblioteca Python para validação de dados e gerenciamento de configurações. Ela permite definir a estrutura de dados desejada usando classes Python normais, com tipos de dados forçados. Para nosso propósito, sua principal vantagem é a capacidade de criar 'modelos de dados' que o LangChain pode usar para instruir o LLM sobre como formatar sua saída e, em seguida, validar se a saída do modelo corresponde a essa estrutura."
      ],
      "metadata": {
        "id": "yu1uUP19UB4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "class InfoCurriculo(BaseModel):\n",
        "    nome: str = Field(description=\"Nome do candidato\")\n",
        "    formacao: str = Field(description=\"Formação do candidato\")\n",
        "    anos_experiencia: float = Field(description=\"Anos de experiência do candidato\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=InfoCurriculo)\n",
        "formato = parser.get_format_instructions()\n",
        "print(formato)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9RjoXt5Ua1A",
        "outputId": "ee717b72-fddd-40f6-d58a-cd8413aa2605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"nome\": {\"description\": \"Nome do candidato\", \"title\": \"Nome\", \"type\": \"string\"}, \"formacao\": {\"description\": \"Formação do candidato\", \"title\": \"Formacao\", \"type\": \"string\"}, \"anos_experiencia\": {\"description\": \"Anos de experiência do candidato\", \"title\": \"Anos Experiencia\", \"type\": \"number\"}}, \"required\": [\"nome\", \"formacao\", \"anos_experiencia\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Extraia as seguintes informações do currículo abaixo:\n",
        "- Nome\n",
        "- Formação\n",
        "- Anos de experiência\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Currículo: \"{resume_text}\"\n",
        "\n",
        "JSON:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"resume_text\"],\n",
        "    partial_variables={\"format_instructions\": formato}\n",
        ")"
      ],
      "metadata": {
        "id": "ZgZa_MAsT-HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm_groq | parser\n",
        "resposta = chain.invoke({\"resume_text\": resume})\n",
        "resposta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VmE-a6nUtwu",
        "outputId": "5f83e8cc-458c-4787-ee66-cce528bc1123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InfoCurriculo(nome='João Silva', formacao='Bacharel em Ciência da Computação pela Universidade Federal de Minas Gerais (UFMG)', anos_experiencia=8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.nome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_uq7RZB_U15z",
        "outputId": "cc2c8b37-8472-4aac-c0ce-ce7ac7a07476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'João Silva'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Abordagem Multi-LLM"
      ],
      "metadata": {
        "id": "6GHsy4isWi6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embora forçar a formatação em um único passo seja conveniente, a complexidade de realizar duas tarefas simultaneamente — extrair a informação e formatá-la perfeitamente — pode, por vezes, degradar a qualidade do resultado. Para mitigar isso, podemos decompor o problema: uma primeira chamada ao LLM foca apenas em extrair a informação em linguagem natural, e uma segunda chamada, que pode usar um modelo mais simples e rápido, foca exclusivamente em converter essa extração para o formato JSON desejado."
      ],
      "metadata": {
        "id": "hm8ZxiXBWsfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_extracao = \"\"\"Extraia as seguintes informações do currículo abaixo:\n",
        "- Nome\n",
        "- Formação\n",
        "- Anos de experiência\n",
        "\n",
        "Apresente as informações extraídas de forma clara.\n",
        "\n",
        "Currículo:\n",
        "{curriculo}\n",
        "\"\"\"\n",
        "prompt_extracao = PromptTemplate.from_template(template_extracao)\n",
        "\n",
        "chain_extracao = prompt_extracao | llm_groq | StrOutputParser()"
      ],
      "metadata": {
        "id": "00_qWkCpWkBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_formatacao = \"\"\"\n",
        "Formate a informação extraída abaixo para um objeto JSON.\n",
        "Siga estritamente o esquema JSON fornecido.\n",
        "\n",
        "Informação Extraída:\n",
        "{info_extraida}\n",
        "\n",
        "Esquema JSON:\n",
        "{esquema_json}\n",
        "\"\"\"\n",
        "prompt_formatacao = PromptTemplate.from_template(template_formatacao)\n",
        "\n",
        "# Modelo LLM para a segunda etapa (pode ser um modelo mais rápido/barato).\n",
        "llm_formatador = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.0 # Temperatura 0 para a tarefa de formatação, que deve ser determinística.\n",
        ")\n"
      ],
      "metadata": {
        "id": "M8XysxN6XHyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multi_llm = (\n",
        "    {\n",
        "        \"info_extraida\": chain_extracao,\n",
        "        \"esquema_json\": lambda x: formato\n",
        "    }\n",
        "    | prompt_formatacao\n",
        "    | llm_formatador\n",
        "    | parser\n",
        ")\n",
        "\n",
        "resposta = chain_multi_llm.invoke(resume)\n",
        "resposta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCfQ0nKRXV6G",
        "outputId": "2c817b8a-d3fd-42b9-af42-f63dfcaa991a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InfoCurriculo(nome='João Silva', formacao='Bacharel em Ciência da Computação pela Universidade Federal de Minas Gerais (UFMG)', anos_experiencia=8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Atividade Prática: Classificador de Notícias Financeiras"
      ],
      "metadata": {
        "id": "fc-FGLe9YSXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora é sua vez de aplicar o que aprendeu! Vamos usar um pequeno conjunto de dados de notícias financeiras para treinar suas habilidades.\n",
        "\n",
        "**Seu objetivo:** Criar uma chain que recebe uma frase de uma notícia e retorna um objeto estruturado com sua polaridade e emocao.\n",
        "\n",
        "Passos:\n",
        "1. **Defina a Estrutura:** Crie uma classe Pydantic chamada ClassificacaoNoticia com os campos nescessários.\n",
        "    - O dataset contém notícias financeiras em português.\n",
        "    - Cada notícia foi resumida em 3 frases, que representam começo (f1), meio (f2) e fim (f3).\n",
        "    - Cada frase possui uma polaridade (positivo, neutro, negativo) e uma emoção universal do ekman (felicidade, tristeza, raiva, nojo, medo, surpreza e desprezo)\n",
        "2. **Crie o Parser:** Instancie um PydanticOutputParser com base na sua classe.\n",
        "3. **Crie o Prompt:** Elabore um PromptTemplate que instrua o LLM a classificar o sentimento de um texto de notícia, usando as instruções de formato do seu parser.\n",
        "4. **Construa a Chain:** Utilize a abordagem Multi-LLM com conversão para objetos com uma única chamada.\n",
        "5. **Teste:** Execute sua implementação para alguns elementos do dataset e imprima os resultados."
      ],
      "metadata": {
        "id": "kB-l8FZJYbzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Curso LLMs/dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WDcUn7KwamvR",
        "outputId": "dde12b55-8afa-4714-c95b-e8c7e08cfa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     news_id headline_sentiment headline_polarity sentence1_sentiment  \\\n",
              "0        683               Medo          Negativo              Neutro   \n",
              "1       4366               Medo          Negativo                Medo   \n",
              "2       4126             Neutro            Neutro          Felicidade   \n",
              "3       3906           Tristeza          Negativo            Tristeza   \n",
              "4        612               Medo          Negativo                Medo   \n",
              "..       ...                ...               ...                 ...   \n",
              "145     3213             Neutro            Neutro              Neutro   \n",
              "146     1164         Felicidade          Positivo            Tristeza   \n",
              "147     1594           Surpresa          Positivo          Felicidade   \n",
              "148     3098           Surpresa          Positivo            Surpresa   \n",
              "149     3941         Felicidade          Positivo          Felicidade   \n",
              "\n",
              "    sentence1_polarity sentence2_sentiment sentence2_polarity  \\\n",
              "0               Neutro              Neutro             Neutro   \n",
              "1             Negativo                Medo           Negativo   \n",
              "2               Neutro            Tristeza           Negativo   \n",
              "3             Negativo              Neutro             Neutro   \n",
              "4             Negativo                Medo           Negativo   \n",
              "..                 ...                 ...                ...   \n",
              "145           Positivo              Neutro           Positivo   \n",
              "146           Negativo          Felicidade           Positivo   \n",
              "147           Positivo            Surpresa           Positivo   \n",
              "148           Positivo                Medo           Negativo   \n",
              "149           Positivo          Felicidade           Positivo   \n",
              "\n",
              "    sentence3_sentiment sentence3_polarity general_sentiment general_polarity  \\\n",
              "0                  Medo           Negativo              Medo         Negativo   \n",
              "1                  Medo           Negativo              Medo         Negativo   \n",
              "2                 Raiva             Neutro            Neutro         Negativo   \n",
              "3              Tristeza           Negativo          Tristeza         Negativo   \n",
              "4                  Medo           Negativo              Medo         Negativo   \n",
              "..                  ...                ...               ...              ...   \n",
              "145              Neutro           Positivo            Neutro         Positivo   \n",
              "146                Medo           Negativo            Neutro         Positivo   \n",
              "147                Medo             Neutro          Surpresa         Positivo   \n",
              "148          Felicidade           Positivo          Surpresa         Positivo   \n",
              "149          Felicidade           Positivo        Felicidade         Positivo   \n",
              "\n",
              "                                              headline  \\\n",
              "0    Esforço para alcance da meta fiscal em 2024 nã...   \n",
              "1    Boletim Focus: mercado eleva perspectiva de in...   \n",
              "2    Caged: Brasil cria 136 mil empregos com cartei...   \n",
              "3    Mercado eleva previsão de inflação para 2023 p...   \n",
              "4    Valor de Pix para casas de apostas cresceu 200...   \n",
              "..                                                 ...   \n",
              "145  Autonomia do Banco Central é incontonável no c...   \n",
              "146  Produção industrial sobe 0,90% em março ante f...   \n",
              "147  Venezuela faz ajuste fiscal e tem menor inflaç...   \n",
              "148  Pacheco diz que sentiu \"compromisso\" de lídere...   \n",
              "149  Governo prevê crescimento de 2% da economia es...   \n",
              "\n",
              "                                                    f1  \\\n",
              "0    Os resultados fiscais do primeiro semestre de ...   \n",
              "1    A expectativa de inflação para 2022 e 2023 aum...   \n",
              "2    Em março de 2022, o Brasil criou 136.189 empre...   \n",
              "3    Os agentes do mercado financeiro elevaram a pr...   \n",
              "4    O presidente do Banco Central, Roberto Campos ...   \n",
              "..                                                 ...   \n",
              "145  O ministro da Fazenda, Fernando Haddad, afirmo...   \n",
              "146  A produção industrial brasileira cresceu 0,90%...   \n",
              "147  Após anos de hiperinflação, a Venezuela regist...   \n",
              "148  O presidente do Senado, Rodrigo Pacheco, afirm...   \n",
              "149  O Ministério da Economia elevou a previsão de ...   \n",
              "\n",
              "                                                    f2  \\\n",
              "0    O desempenho das receitas líquidas foi positiv...   \n",
              "1    Apesar do aumento nas estimativas de inflação,...   \n",
              "2    O setor de serviços foi o principal responsáve...   \n",
              "3    Apesar de as estimativas para a inflação de cu...   \n",
              "4    Ele destacou um aumento superior a 200% no val...   \n",
              "..                                                 ...   \n",
              "145  Ele anunciou que o novo arcabouço fiscal pode ...   \n",
              "146  No acumulado do primeiro trimestre, a indústri...   \n",
              "147  Essa melhora foi impulsionada por cortes nos g...   \n",
              "148  Durante reunião com o ministro da Fazenda, Fer...   \n",
              "149  Essa melhora nas projeções reflete a percepção...   \n",
              "\n",
              "                                                    f3  \n",
              "0    Apesar das medidas de contenção adotadas, a su...  \n",
              "1    O cenário econômico aponta para uma leve melho...  \n",
              "2    Apesar do crescimento, o salário médio de admi...  \n",
              "3    A projeção para o PIB de 2023 foi ajustada par...  \n",
              "4    Campos Neto afirmou que o BC está atento à sit...  \n",
              "..                                                 ...  \n",
              "145  Haddad também criticou as altas taxas de juros...  \n",
              "146  Apesar do crescimento geral, 20 dos 25 ramos i...  \n",
              "147  No entanto, o governo mantém uma política de r...  \n",
              "148  Especialistas elogiaram a regra por sua transp...  \n",
              "149  As expectativas do mercado também se ajustaram...  \n",
              "\n",
              "[150 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5621665f-f5f6-4e25-b923-3bfe25822365\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>headline_sentiment</th>\n",
              "      <th>headline_polarity</th>\n",
              "      <th>sentence1_sentiment</th>\n",
              "      <th>sentence1_polarity</th>\n",
              "      <th>sentence2_sentiment</th>\n",
              "      <th>sentence2_polarity</th>\n",
              "      <th>sentence3_sentiment</th>\n",
              "      <th>sentence3_polarity</th>\n",
              "      <th>general_sentiment</th>\n",
              "      <th>general_polarity</th>\n",
              "      <th>headline</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>683</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Esforço para alcance da meta fiscal em 2024 nã...</td>\n",
              "      <td>Os resultados fiscais do primeiro semestre de ...</td>\n",
              "      <td>O desempenho das receitas líquidas foi positiv...</td>\n",
              "      <td>Apesar das medidas de contenção adotadas, a su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4366</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Boletim Focus: mercado eleva perspectiva de in...</td>\n",
              "      <td>A expectativa de inflação para 2022 e 2023 aum...</td>\n",
              "      <td>Apesar do aumento nas estimativas de inflação,...</td>\n",
              "      <td>O cenário econômico aponta para uma leve melho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4126</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Raiva</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Caged: Brasil cria 136 mil empregos com cartei...</td>\n",
              "      <td>Em março de 2022, o Brasil criou 136.189 empre...</td>\n",
              "      <td>O setor de serviços foi o principal responsáve...</td>\n",
              "      <td>Apesar do crescimento, o salário médio de admi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3906</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Mercado eleva previsão de inflação para 2023 p...</td>\n",
              "      <td>Os agentes do mercado financeiro elevaram a pr...</td>\n",
              "      <td>Apesar de as estimativas para a inflação de cu...</td>\n",
              "      <td>A projeção para o PIB de 2023 foi ajustada par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>612</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Valor de Pix para casas de apostas cresceu 200...</td>\n",
              "      <td>O presidente do Banco Central, Roberto Campos ...</td>\n",
              "      <td>Ele destacou um aumento superior a 200% no val...</td>\n",
              "      <td>Campos Neto afirmou que o BC está atento à sit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>3213</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Autonomia do Banco Central é incontonável no c...</td>\n",
              "      <td>O ministro da Fazenda, Fernando Haddad, afirmo...</td>\n",
              "      <td>Ele anunciou que o novo arcabouço fiscal pode ...</td>\n",
              "      <td>Haddad também criticou as altas taxas de juros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>1164</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Tristeza</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Produção industrial sobe 0,90% em março ante f...</td>\n",
              "      <td>A produção industrial brasileira cresceu 0,90%...</td>\n",
              "      <td>No acumulado do primeiro trimestre, a indústri...</td>\n",
              "      <td>Apesar do crescimento geral, 20 dos 25 ramos i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>1594</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Venezuela faz ajuste fiscal e tem menor inflaç...</td>\n",
              "      <td>Após anos de hiperinflação, a Venezuela regist...</td>\n",
              "      <td>Essa melhora foi impulsionada por cortes nos g...</td>\n",
              "      <td>No entanto, o governo mantém uma política de r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>3098</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Medo</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Surpresa</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Pacheco diz que sentiu \"compromisso\" de lídere...</td>\n",
              "      <td>O presidente do Senado, Rodrigo Pacheco, afirm...</td>\n",
              "      <td>Durante reunião com o ministro da Fazenda, Fer...</td>\n",
              "      <td>Especialistas elogiaram a regra por sua transp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>3941</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Felicidade</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Governo prevê crescimento de 2% da economia es...</td>\n",
              "      <td>O Ministério da Economia elevou a previsão de ...</td>\n",
              "      <td>Essa melhora nas projeções reflete a percepção...</td>\n",
              "      <td>As expectativas do mercado também se ajustaram...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5621665f-f5f6-4e25-b923-3bfe25822365')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5621665f-f5f6-4e25-b923-3bfe25822365 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5621665f-f5f6-4e25-b923-3bfe25822365');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5641e6ed-786a-42a5-8b3a-118939ff1c2d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5641e6ed-786a-42a5-8b3a-118939ff1c2d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5641e6ed-786a-42a5-8b3a-118939ff1c2d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4d53545d-ddbc-4c35-988c-b7ecdc46f375\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d53545d-ddbc-4c35-988c-b7ecdc46f375 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"news_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1326,\n        \"min\": 55,\n        \"max\": 4664,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          1524,\n          3963,\n          4664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Neutro\",\n          \"Nojo\",\n          \"Medo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negativo\",\n          \"Neutro\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Medo\",\n          \"Nojo\",\n          \"Neutro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Neutro\",\n          \"Negativo\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Neutro\",\n          \"Medo\",\n          \"Desprezo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Neutro\",\n          \"Negativo\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence3_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Raiva\",\n          \"Desprezo\",\n          \"Medo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence3_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negativo\",\n          \"Neutro\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Medo\",\n          \"Neutro\",\n          \"Desprezo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Negativo\",\n          \"Neutro\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"Taxa de desemprego fica em 7,6% em janeiro, com crescimento da ocupa\\u00e7\\u00e3o e rendimento\",\n          \"Infla\\u00e7\\u00e3o de junho volta a subir e IPCA fecha em 0,67% com alta dos alimentos\",\n          \"Desemprego recua para 13,7% em julho e atinge 14,1 milh\\u00f5es, diz IBGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"A taxa de desemprego ficou em 7,6% no trimestre encerrado em janeiro de 2024, mantendo-se est\\u00e1vel em rela\\u00e7\\u00e3o aos tr\\u00eas meses anteriores, enquanto recuou 0,7 ponto percentual na compara\\u00e7\\u00e3o anual.\",\n          \"A infla\\u00e7\\u00e3o medida pelo IPCA em junho foi de 0,67%, elevando o acumulado de 12 meses para 11,89%, superando o teto da meta do Banco Central.\",\n          \"A taxa de desemprego no Brasil caiu para 13,7% no trimestre encerrado em julho, em compara\\u00e7\\u00e3o com 14,7% no trimestre anterior, refletindo uma recupera\\u00e7\\u00e3o do mercado de trabalho.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"A popula\\u00e7\\u00e3o ocupada atingiu 100,6 milh\\u00f5es de trabalhadores, registrando crescimento de 0,4% em rela\\u00e7\\u00e3o ao trimestre anterior e de 2% em rela\\u00e7\\u00e3o a janeiro de 2023, impulsionada por setores como transporte e servi\\u00e7os financeiros.\",\n          \"Apesar de sinais de que a infla\\u00e7\\u00e3o possa estar atingindo seu pico, riscos externos e press\\u00f5es em servi\\u00e7os continuam presentes, mantendo a expectativa de alta de juros e infla\\u00e7\\u00e3o em dois d\\u00edgitos at\\u00e9 o meio do ano.\",\n          \"Em agosto, foram criados 372,3 mil postos de trabalho, impulsionados pelo avan\\u00e7o econ\\u00f4mico e programas de manuten\\u00e7\\u00e3o de emprego.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"O rendimento m\\u00e9dio real dos trabalhadores aumentou 1,6% no trimestre e 3,8% no ano, atingindo R$ 3.078, contribuindo para uma massa de rendimento recorde de R$ 305,1 bilh\\u00f5es.\",\n          \"Todos os grupos de produtos tiveram alta de pre\\u00e7os, com destaque para alimentos, transporte e sa\\u00fade, refletindo a retomada de consumo e os efeitos de fatores internos e externos na economia brasileira.\",\n          \"No entanto, economistas alertam que a desocupa\\u00e7\\u00e3o deve permanecer elevada por um per\\u00edodo prolongado devido ao descompasso entre oferta e demanda de m\\u00e3o de obra.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificacaoNoticia(BaseModel):\n",
        "    pass"
      ],
      "metadata": {
        "id": "JWDQdOHAYV6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão do Módulo"
      ],
      "metadata": {
        "id": "AL6KpDe-a0cM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parabéns! Você configurou seu ambiente, aprendeu a usar o LangChain para interagir com um LLM e, o mais importante, implementou uma forma robusta de obter saídas estruturadas. O objeto `ClassificacaoSentimento` que recebemos no final é previsível e fácil de usar em qualquer sistema.\n",
        "\n",
        "Essa habilidade é o alicerce sobre o qual construiremos técnicas mais sofisticadas. No próximo módulo, vamos nos aprofundar na Engenharia de Prompt para melhorar drasticamente a qualidade e a precisão das respostas do modelo."
      ],
      "metadata": {
        "id": "99oH2iY2a4Ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências"
      ],
      "metadata": {
        "id": "pnAFALv-bFvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Chase, H. (2022). LangChain. GitHub. https://github.com/langchain-ai/langchain"
      ],
      "metadata": {
        "id": "5YooXhEKbH5Z"
      }
    }
  ]
}